---
title: Wallace Session `r Sys.Date()`
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knit_engines$set(asis = function(options) {
  if (options$echo && options$eval) knit_child(text = options$code)
})
knitr::opts_chunk$set(message = FALSE, warning = FALSE, eval = FALSE)
```

```{r vars, include = FALSE, eval = TRUE}
# comp1
occs.db <- "{{occsSource}}" != "user"
occs.user <- "{{occsSource}}" == "user"
```

Please find below the R code history from your *Wallace* v1.0.4 session. 

You can reproduce your session results by running this R Markdown file in RStudio. 

Each code block is called a "chunk", and you can run them either one-by-one or all at once by choosing an option in the "Run" menu at the top-right corner of the "Source" pane in RStudio. 

For more detailed information see <http://rmarkdown.rstudio.com>).

### Package installation

Wallace uses the following R packages that must be installed and loaded before starting.
```{r loadPkgs}
library(spocc)
library(spThin)
library(dismo)
library(rgeos)
library(ENMeval)
```

Wallace also includes several functions developed to help integrate different packages and some additional functionality. For this reason, it is necessary to load the file `functions.R`, The function `system.file()` finds this script, and `source()` loads it.

```{r loadFunctions}
source(system.file('shiny/funcs', 'functions.R', package = 'wallace'))
```

## Record of analysis for *`r "{{spName}}"`*.

```{asis occsTitle}
### Obtain Occurrence Data
```

```{asis, echo = occs.db, eval = occs.db, include = occs.db}
You searched the `r "{{occsSource}}"` database for *`r "{{spName}}"`*, limited to `r {{occsNum}}` records. 
```

```{r occSearch, echo = occs.db, include = occs.db}
# query selected database for occurrence records
db.query <- spocc::occ(query = "{{spName}}", from = "{{occsSource}}", limit = {{occsNum}}, has_coords = TRUE)
# make a formatted version of the species name for spocc
spName <- formatSpName("{{spName}}")
# retrieve data table from spocc object
db.data <- db.query[["{{occsSource}}"]]$data[[spName]]
# remove rows with duplicate coordinates
dupCoords <- duplicated(db.data[c('longitude', 'latitude')])
occs <- db.data[!dupCoords,]
# make sure latitude and longitude are numeric (sometimes they are characters)
occs$latitude <- as.numeric(occs$latitude)
occs$longitude <- as.numeric(occs$longitude)
# give all records a unique ID
occs$occID <- row.names(occs)
# extract occurrence coordinates
occs.xy <- occs[c('longitude', 'latitude')]
```

```{asis, echo = occs.user, eval = occs.user, include = occs.user}
User CSV path with occurrence data. If the CSV file is not in the current workspace, change to the correct file path (e.g. "/Users/darwin/Documents/occs.user").
```

```{r occInput, echo = occs.user}
# NOTE: provide the path to the folder that contains the rasters
d.occs <- ''
# create path to user occurrences csv file
userOccs.path <- file.path(d.occs, "{{occsCSV}}")
# read in csv
useroccs.user <- read.csv(userOccs.path, header = TRUE)
# remove rows with duplicate coordinates
occs.dups <- duplicated(useroccs.user[c('longitude', 'latitude')])
occs <- useroccs.user[!occs.dups,]
# extract occurrence coordinates
occs.xy <- occs[c('longitude', 'latitude')]
```


```{asis, echo = poccs.any, eval = poccs.any, include = poccs.any}
### Process Occurrence Data
```

```{asis, echo = poccs.rem, eval = poccs.rem, include = poccs.rem}
Remove the occurrence localities with the following IDs: `r {{occsRemoved}}`.
```

```{r poccs.rem, echo = poccs.rem, include = poccs.rem}
# remove the rows that match the occIDs selected
occs <- occs %>% filter(!(occID %in% {{occsRemoved}}))
```

```{asis, echo = poccs.sel, eval = poccs.sel, include = poccs.sel}
The following code recreates the polygon used to select occurrences to keep in the analysis.
```

```{r occsSelect, echo = poccs.sel, include = poccs.sel}
selCoords <- data.frame(x = {{occsSelX}}, y = {{occsSelY}})
selPoly <- sp::SpatialPolygons(list(sp::Polygons(list(sp::Polygon(selCoords)), ID=1)))
intersect <- sp::over(occs.xy, selPoly)
intersect.rowNums <- as.numeric(which(!(is.na(intersect))))
occs <- occs[intersect.rowNums, ]
```

```{asis, echo = poccs.thin, eval = poccs.thin, include = poccs.thin}
Spatial thinning selected. Thin distance selected is `r {{thinDist}}` km.
```

```{r doThin, echo = poccs.thin, include = poccs.thin}
output <- spThin::thin(occs, 'latitude', 'longitude', 'name', thin.par = {{thinDist}}, reps = 100, locs.thinned.list.return = TRUE, write.files = FALSE, verbose = FALSE)
```

```{asis, echo = poccs.thin, eval = poccs.thin, include = poccs.thin}
Since spThin did 100 iterations, there are 100 different variations of how it thinned your occurrence localities. As there is a stochastic element in the algorithm, some iterations may include more localities than the others, and we need to make sure we maximize the number of localities we proceed with.
```

```{r doThin2, echo = poccs.thin, include = poccs.thin}
# find the iteration that returns the max number of occurrences
maxThin <- which(sapply(output, nrow) == max(sapply(output, nrow)))
# if there's more than one max, pick the first one
maxThin <- output[[ifelse(length(maxThin) > 1, maxThin[1], maxThin)]]  
# subset occs to match only thinned occs
occs <- occs[as.numeric(rownames(maxThin)),]  
```

