---
title: "Wallace Vignette"
author: 
- "Cory Merow"
- "Jamie M. Kass"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Wallace Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = FALSE, include=FALSE}
library(knitr)
knitr::opts_chunk$set(collapse=TRUE, message=FALSE, warning=FALSE, comment="#>")
```

# Preface
This vignette and any others in the `wallace` package will be updated regularly in accordance with ongoing development. This vignette was written for *Wallace* v. 1.0.4, so if you are using a more updated version, some things will be different. We plan to update this vignette periodically.

# Introduction
*Wallace* v1.0.4 is an `R`-based GUI application for modeling species niches and distributions, and evaluating the results. We will refer to these models as species distribution models (SDMs), and we will not explain them at length here: the purpose of this vignette is to show users how to use *Wallace*. As you read through, you will be pointed to some sources of detailed info within the application for reference.

*Wallace* has many qualities which we think make it a good example of next-generation scientific software: it's 1) open, 2) expandible, 3) flexible, 4) interactive, 5) instructive, and 6) reproducible. The application features an pannable/zoomable map and dynamic plots and tables. Data for the models can be download from online databases or uploaded by the user, and most results can be downloaded, including the option to save R code that can reproduce your analysis. For more details, including on SDMs, please see our [publication](http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12945/full) in Methods in Ecology and Evolution. The citation is below: 

Kass JM, Vilela B, Aiello-Lammens ME, Muscarella R, Merow C, Anderson RP. Wallace: A flexible platform for reproducible modeling of species niches and distributions built for community expansion. *Methods Ecol Evol*. 2018;00:1â€“6. https://doi.org/10.1111/2041-210X.12945

The *Wallace* project's [main page](https://wallaceecomod.github.io/) has links to the [Google Group](https://groups.google.com/forum/#!forum/wallaceecomod), the official [email](mailto:wallaceecomod@gmail.com), the [CRAN page](https://CRAN.R-project.org/package=wallace) hosting the stable version, and the [Github development page](https://github.com/wallaceEcoMod/wallace).

# Setup
For `wallace` to work, **you should be using the latest version of R** (or at least later than version 3.2.1). Download for 
[Windows](https://cran.r-project.org/bin/windows/base/) or [Mac](https://cran.r-project.org/bin/macosx/).

Let's first install and run *Wallace*. 
```{r, eval=FALSE}
# install the package
install.packages('wallace')
# load the package
library(wallace)
# run the app
run_wallace() 
```

The *Wallace* GUI will open in your web browser and the R command line will be occupied (you only get a prompt back by pushing 'escape'). If you'd like to use your typical R command line, open a terminal window, type `R` to start R, and then run the lines above in that window. This will tie up your terminal window but not your R command line (e.g. RStudio, or the R GUI). **You need to avoid exiting your browser window or closing the R window that initiated *Wallace*, or you'll have to start over!** Using the terminal looks like this:  

```{r, out.width = "600px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace_Introb.png")
```

Typing `run_wallace()` will run *Wallace* in your web browser. 

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace_Intro.png")
```

# Obtain Occurrence Data

You will notice tabs along the top: these are the *components*, which represent discrete steps of the analysis, and you will be stepping sequentially through them. First, click on **Occ Data**. On the left side, there is a window where all the user interface controls are (buttons, text inputs, etc.). You can see that **module** **_Query Database_** is currently selected. *Modules* are discrete analysis options within each component, and can be contributed by other researchers. You'll see that another module exists for this component: **_User-specified Occurrences_**. This module lets you upload your own occurrence data. Try choosing this module instead and notice that the controls change, then click back to **_Query Database_**.

On the right side is the interaction window, which has tabs representing the map, occurrence records table, results window, and guidance text windows for both the component and module levels. At this stage of the analysis, no results exist, and we have no data yet for the table, but you can view the guidance text now. This text was written by the developers to prepare users for each component and module *methodologically* (what the tools do) and *theoretically* (why we should use them). The guidance text also references scientific papers from the ecology literature for more detailed reading. Please get into the habit of consulting these before undertaking analyses, as they should give you a more solid foundation for moving forward.

Begin by downloading 75 records of *Tremarctos ornatus* (spectacled bear) from GBIF. After the download is complete, notice the message in the log window, and click on the table tab to view more information on the records. The developers chose the fields that are displayed based on their general relevance to SDMs. The red arrow shows the button you can press to download a .csv file of these records, which has all the original database fields.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace1a.png")
```

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace1b.png")
```

At this stage, it is a good idea to read the component and module guidance text by clicking on their tabs.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace1c.png")
```

# Process Occurrence Data

The next component, **Process Occs**, gives you access to some data-cleaning tools. If you want to model the distribution of *T. ornatus* in South America, you can remove the odd points found in other parts of the world. For databases like GBIF that accumulate lots of data from various sources, there are inevitably always some dubious localities that may represent a museum collection instead of a natural occurrence, or simply have incorrect coordinates. Click the point to see its info and then enter the ID in the control window on the left to remove it.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace2a.png")
```

Alternatively, you can select the points you want to use by clicking on the module "Select Occurrences On Map". Click on the polygon icon on the map and draw a polygon around the points you want to select. When you are done, click "finish". Now click "Select Occurrences".

Insert image here

The samples may exhibit spatial autocorrelation, which can lead to bias in the environmental signal. For example, there might be a cluster of records near cities because these are mostly from iNaturalist (citizen science) and most citizen scientists live near cities. You can reduce spatial bias by thinning the points to make sure they're all at least 20 km from one another. That leaves 32 points for modeling (yours may be different).

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace2b.png")
```

If you zoom in on the map, you will see the points that were removed in blue.

Insert image here.

# Obtain Environmental Data

Next, you will need to obtain climatic variables for your model. Click on the component "Env Data". Worldclim is a global climate database that is very popular because it is easily accessible at fine resolutions. The variables are based on interpolations of weather station data for temperature and precipitation, and the coverage is better for areas with more weather stations (especially in developed countries). The **bioclim** predictors are summaries of temperature and precipitation that have been determined to have some biological significance. They're all listed [here](http://www.worldclim.org/bioclim).

Choose the **10 arcmin** bioclimatic variables and press download. The first time you use *Wallace* these data are downloaded to your hard drive; after that they will simply be loaded from this local directory. Finer resolutions will take longer to download. 

Insert text about clicking on the results tab.
Insert one more image.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace3a.png")
```


# Process Environmental Data

Now we need to choose the study extent for modeling. This simply means we have to define a region from which to draw "background" values for model fitting. Methods like Maxent are known as presence-background techniques because they compare the predictor variable values at background locations to those at the occurrence points. In making this decision, we want to try and avoid areas the species has historically been unable to move to, for example, regions beyond a barrier like a mountain range or large river that the species cannot traverse. If we were to include these areas, we'd be sending a false signal to the model that these areas are part of the "background" and thus not suitable -- they might be occupied if the species could move there. Please see the guidance text for more details.

We can explore the different options for delineating the study extent here. Press the **Mask** button to trim the environmental layers to this polygon.

Insert text about Step 2.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace4a.png")
```

# Partition occurrences

Random k-fold

In order to check whether you've built a model with strong predictive ability, you theoretically need independent data to validate it. When no independent datasets exist, one solution is to partition your data into subsets that we assume are independent of each other, then sequentially build a model on all the subsets but one and evaluate this model on the left-out subset. This is known as *k*-fold cross validation (where *k* is the total number of subsets), and it is quite prevalent in statistics, especially the field of machine learning. After this sequential modeling building exercise is complete, *Wallace* builds a model using **all** the data and summarizes the statistics for all the partitions.

There's a whole literature on how to best partition data for modeling. One option is to simply partition randomly, but with spatial data we run the risk that the groups are not spatially independent of each other. An arguably better option is to partition using spatial blocking -- for example, by drawing lines on a map to divide the data. Spatial partitioning with *k*-fold cross validation forces the model to predict to regions that are distant from those used to train the model. If the model has accurate predictions on average, we can determine that the model likely has good transferability, as it can transfer well to new values of predictor variables (as distant areas are usually more environmentally different than close areas). Please refer to the guidance text for more details on all the types of partitioning offered in *Wallace*.

Below, we show some options for spatial partitioning.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace5a.png")
```

Insert text about non-spatial partition.Block 4, aggregation factor 2.
Insert image.


Take a moment to scroll through the log window at the top of the screen and review all the steps you've taken so far.

# Model

L, LQ, H and LQH R.M. 1-3 step by .5 no clamping

Let's now finally build a Maxent model. Maxent is a machine learning method that can fit complex (i.e. curvy) functions to patterns in the data. If you construct it with particular settings it can also become very similar to a generalized linear model (GLM). Thus, Maxent can conver a wide spectrum of complexity. For more details, please consult the guidance text.

Below, we've chosen some modeling options:

  - Select LQH features. These are the shapes that can be fit to the data: 
    + L = Linear, e.g. temp + precip
    + Q = Quadratic, e.g. temp^2 + precip^2
    + P = Product, e.g. interaction terms of the form temp*precip
    + H = Hinge, e.g. piecewise linear functions, like splines
    
Hinge features can fit all possible slopes between two data points, enabling a very flexible function, similar to a generalized additive model (GAM).

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/hinge_threshold.png")
```

  - Select regularization multipliers between 1-3
    + Regularization is a way to reduce model complexity.
    + Higher values = smoother, less complex models. Basically, all predictor variable coefficients are shrunk progressively until some reach 0, when they drop out of the model. Only those variables with the greatest predictive contribution remain in the model.
  - RM Step Value = 1
    + This represents how large of step to take between values in the slide bar above.

The modeling takes about 2 minutes. We're building 1 feature class combination \* 3 regularization multipliers \* 4 data partitions = 12 models. Further, LQH will enable significant complexity in the response, which takes a bit longer than simpler models.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace6a.png")
```

Notice that the first time we ran this we got an error, which you may get too. You need to put the maxent software (maxent.jar) in the directory where *Wallace* will look for it. This is due to the particular way the R package `dismo` was constructed, and out of our control. We are however working on alternative ways to approach this. As the log window indicates, download the file and put it in the appropriate directory. Then click **Run Models** again. 

The result is a table of evaluation statistics, courtesy of R package `ENMeval`, to compare the different models you just built. There should be 3 rows: one for each of the regularization multipliers. The statistics from the 4 models from our partitions were averaged -- these are labeled with "test". 

How do we choose the "best" model? There is a mountain of literature about this, and there is really no concrete answer. AUC and OR (omission rate) were calculated using our spatial partitions, and AIC was instead calculated using the model prediction of our background extent. Although AIC does not incorporate the cross validation results, it does explicitly penalize model complexity -- models with more parameters have a worse AIC score. It's really up to the user to decide, and the guidance text has some references which should help you learn more.

For illustrative purposes, we want to maximize transferability, and will choose the model with regularization mulitiplier 2. This model has the highest average testing AUC at 0.804 (note: current image is incorrect and will be fixed with next version).

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace6b.png")
```

# Visualize
Now let's plot the performance statistics across models. Please explore the options a bit.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace7a.png")
```

To evaluate whether the model makes biological sense, we can look at **response curves** that define how each predictor (x-axis) relates to suitability (y-axis). The shape of the response seems reasonable -- there are places where the temperature range is both too wide and too narrow for *A. rubrum*. The jagged parts intuitively seem like overfitting. Why would a species, over an evolutionary time span, have an abrupt dip in response to temperature range (as seen around 430)? (Note that the units are degrees C x 100; WorldClim serves the files this way to compress them.)

Below is the response curve for annual temperature range (bio7).

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace7b.png")
```

map prediction is LQ 1.5 cloglog no threshold

We can also map the predictions. At first glance it looks like a good model because the presence points correspond to regions of higher suitability. Also, as we chose a model with relatively good transferability, we can be more confident we have avoiding overfitting to some extent.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace7c.png")
```

# Project

Next, we can evaluate the model's ability to project first to new locations (extending the domain) and new times (2070). "Projecting" simply means plugging in new values to our mathematical model and getting a new response. Think of it like drawing some new range on our response curves and finding the resulting suitability. This could possibly be outside the range we saw previously, and the lines would need to be extended (unless clamping is chosen -- see guidance text).

This is potentially confusing -- didn't the cross validation step do this too? The cross validation with spatial partitioning step sequentially forced models to predict to new areas, and the average testing AUC summarized their ability to transfer accurately. However, the model we selected was built with **all** the data. We are now taking this model and projecting it to predictor variable value ranges that were potentially never used in model training. Thus, these values for different places and times might be completely new to our model, and could be so different that we may be uncertain in the accuracy of our projection. Please see the guidance text for more details. 

First, let's draw a polygon like the one below. Next, press `Select` and then `Project` to build the new map.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace8a.png")
```

Below are the predictions to a much larger region. It looks like northern Canada should get ready for a red maple invasion... So it appears we've fit a response that doesn't generalize well to other regions. Although we tried to maximize transferability, the spatial partitions did not capture variable ranges that were wide enough to include those in northern Canada. This is not a failure in the analysis -- it's just the reality of uncertainty in modeling. 

One way to determine how that happened is to look back at the response curves to see which variables are contributing to high suitability in northern Canada. We could also construct MESS plots to see where the areas are that are most different from those used to train the model (will add with next version). Please see the guidance text for details.

We can also project to future climate scenarios. Select the options as below and forecast the future range of *A. rubrum* under an extreme climate change scenario.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace8b.png")
knitr::include_graphics("vignette_img/Wallace8c.png")
knitr::include_graphics("vignette_img/Wallace8d.png")
```

# Extracting the code

A major advantage of *Wallace* compared to other GUI-based software is that you can extract all the code used to run the analysis. This allows you to rerun the analysis session, share it, or modify it. The code can be downloaded in several ways, but the **R Markdown** format, which is a convienient format for combining R code and text, can be run directly in R. For .pdf downloads, some version of TeX is necessary. Please see the text on this page for more details.

To download the code, select Rmd and click Download.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/Wallace9a.png")
```

Now, you should have an .Rmd file that contains your complete analysis. Rmd files combine regular text with **code chunks**, shown by the red arrow below. Modules from *Wallace* are indicated as headers denoted by **###**. For a quick reference to Rmd syntax, see [here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/WallaceRMDa.png")
```

You might want to open a new R window and try running some of this code. Just note that if you close your *Wallace* session you'll lose your progress in the web browser (but your Rmd will be unaffected). If you use RStudio, you can open this Rmd and click **knit** to compile your workflow into a sharable html document. 

Note that you can change anything you like in this code to build upon your workflow. We envision that future versions of *Wallace* will enable you to upload such modified Rmds to *Wallace* to fill in all the options you chose and pick up where you left off in a previous analysis in the GUI.

At the moment we don't have anything built into *Wallace* for post-processing, so you can use R directly to build from the code created above.

# Improving the model

Let's revisit that uncertain prediction into northern Canada. This issue derived from a poor choice of modeling domain and an overfit model. Try rerunning the analysis by extending the domain to include many locations where the species does not occur (see below) and using a simpler model that includes only linear and quadratic features.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/WallaceNexta.png")
```

Here are the improved predictions that avoid prediction in northern Canada.

```{r, out.width = "800px", echo = FALSE}
knitr::include_graphics("vignette_img/WallaceNextb.png")
```


